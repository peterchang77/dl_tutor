{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In this tutorial we will review key modern CNN architecture motifs and discuss implementation strategies using Tensorflow 2 / Keras.\n",
    "\n",
    "**Modern Architectures**\n",
    "\n",
    "* residual connection\n",
    "* bottleneck operation\n",
    "* Inception module\n",
    "* Squeeze-and-Excite (SE) module\n",
    "\n",
    "This tutorial is part of the class **Introduction to Deep Learning for Medical Imaging** at University of California Irvine (CS190); more information can be found at: https://github.com/peterchang77/dl_tutor/tree/master/cs190."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56d3oMiMw8Wm"
   },
   "source": [
    "# Google Colab\n",
    "\n",
    "The following lines of code will configure your Google Colab environment for this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable GPU runtime\n",
    "\n",
    "Use the following instructions to switch the default Colab instance into a GPU-enabled runtime:\n",
    "\n",
    "```\n",
    "Runtime > Change runtime type > Hardware accelerator > GPU\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jarvis library\n",
    "\n",
    "In this notebook we will Jarvis, a custom Python package to facilitate data science and deep learning for healthcare. Among other things, this library will be used for low-level data management, stratification and visualization of high-dimensional medical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Install jarvis (only in Google Colab or local runtime)\n",
    "% pip install jarvis-md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "Use the following lines to import any additional needed libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from tensorflow import losses, optimizers\n",
    "from tensorflow.keras import Input, Model, models, layers\n",
    "from jarvis.train import datasets\n",
    "from jarvis.utils.display import imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The data used in this tutorial will consist of brain tumor MRI exams derived from the MICCAI Brain Tumor Segmentation Challenge (BRaTS). More information about he BRaTS Challenge can be found here: http://braintumorsegmentation.org/. Each single 2D slice will consist of one of four different sequences (T2, FLAIR, T1 pre-contrast and T1 post-contrast). In this exercise, we will use this dataset to derive a model for slice-by-slice tumor detection. The custom `datasets.download(...)` method can be used to download a local copy of the dataset. By default the dataset will be archived at `/data/raw/mr_brats_2020`; as needed an alternate location may be specified using `datasets.download(name=..., path=...)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Download dataset\n",
    "datasets.download(name='mr/brats-2020-mip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once downloaded, the `datasets.prepare(...)` method can be used to generate the required python Generators to iterate through the dataset, as well as a `client` object for any needed advanced functionality. As needed, pass any custom configurations (e.g. batch size, normalization parameters, etc) into the optional `configs` dictionary argument. Additionally, we will re-use this dataset for different tasks (e.g., tumor detection, survival prediction, etc). To specificy the correct Generator template file, pass a designated `keyword` string; in this weeks tutorial, we will be using 2D images of shape `(240, 240)` and performing global (entire-slice) tumor prediction using the keyword string `240*glb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prepare generators\n",
    "gen_train, gen_valid, client = datasets.prepare(name='mr/brats-2020-mip', keyword='mip*glb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, each iteration yields two variables, `xs` and `ys`, each representing a dictionary of model input(s) and output(s). In the current example, there is just a single input and output. Let us examine the generator data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Yield one example\n",
    "xs, ys = next(gen_train)\n",
    "\n",
    "# --- Print dict keys\n",
    "print('xs keys: {}'.format(xs.keys()))\n",
    "print('ys keys: {}'.format(ys.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Print data shape\n",
    "print('xs shape: {}'.format(xs['dat'].shape))\n",
    "print('ys shape: {}'.format(ys['tumor'].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wD5ejoTbx1_0"
   },
   "source": [
    "### BRATS Data\n",
    "\n",
    "Let us get to know this data a little bit more. The input images in the variable `dat` are matrices of shape `1 x 240 x 240 x 4`. Note that even though the images here are 2D in shape, the full matrix is a 3D tensor `(z, y, x)` where `z = 1` in this implementation. Note that although the 3rd z-axis dimension is redundant here (for a single slice input), many of our more complex models and architectures will commonly require a full 3D tensor. Because of this, we will directly use 3D convolutions throughout the tutorial materials for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 479,
     "status": "ok",
     "timestamp": 1526486098306,
     "user": {
      "displayName": "Peter Chang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108798638501675293926"
     },
     "user_tz": 420
    },
    "id": "rrziy2-2x1_2",
    "outputId": "a250e47f-4f32-456c-bbfe-a8a087b43c4e"
   },
   "outputs": [],
   "source": [
    "print(xs['dat'][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hx31sEGhx1_-"
   },
   "source": [
    "The four channels represent four different input MRI sequences. Each sequence is used to evaluate for a different tissue quality. T2 and FLAIR are used to evaluate edema (fluid) that results from brain injury. T1 images are used to evaluate anatomy and breakdown of the blood-brain-barrier through contrast leakge.  \n",
    "\n",
    "```\n",
    "dat[..., 0] = FLAIR\n",
    "dat[..., 1] = T1 precontrast\n",
    "dat[..., 2] = T1 postcontrast\n",
    "dat[..., 3] = T2\n",
    "```\n",
    "\n",
    "To visualize these different modalities run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1069
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1488,
     "status": "ok",
     "timestamp": 1526486099897,
     "user": {
      "displayName": "Peter Chang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108798638501675293926"
     },
     "user_tz": 420
    },
    "id": "pOKYq_VPx2AC",
    "outputId": "3d85c3fb-4050-443d-e93a-4768fc3b4897"
   },
   "outputs": [],
   "source": [
    "imshow(xs['dat'][..., 0], title='FLAIR')\n",
    "imshow(xs['dat'][..., 1], title='T1 precontrast')\n",
    "imshow(xs['dat'][..., 2], title='T1 postcontrast')\n",
    "imshow(xs['dat'][..., 3], title='T2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model inputs\n",
    "\n",
    "For every input in `xs`, a corresponding `Input(...)` variable can be created and returned in a `inputs` dictionary for ease of model development:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create model inputs\n",
    "inputs = client.get_inputs(Input)\n",
    "\n",
    "print(inputs.keys())\n",
    "print(inputs['dat'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the equivalent Python code to generate `inputs` would be:\n",
    "\n",
    "```python\n",
    "inputs = {}\n",
    "inputs['dat'] = Input(shape=(1, 240, 240, 1))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the definition of a residual layer:\n",
    "\n",
    "![Diagramtric Representation](https://raw.githubusercontent.com/peterchang77/dl_tutor/master/cs190/spring_2021/notebooks/detection/pngs/residual.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the prior tutorial, let us set up the same lambda functions for CNN definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define kwargs dictionary\n",
    "kwargs = {\n",
    "    'kernel_size': (1, 3, 3),\n",
    "    'padding': 'same'}\n",
    "\n",
    "# --- Define lambda functions\n",
    "conv = lambda x, filters, strides : layers.Conv3D(filters=filters, strides=strides, **kwargs)(x)\n",
    "norm = lambda x : layers.BatchNormalization()(x)\n",
    "relu = lambda x : layers.ReLU()(x)\n",
    "\n",
    "# --- Define stride-1, stride-2 blocks\n",
    "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n",
    "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=(1, 2, 2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of a residual function is reasonably straightforward as recent versions of Tensorflow / Keras layers can utilize the native Python addition `+` operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define blocks\n",
    "l1 = conv1(16, inputs['dat'])\n",
    "l2 = conv1(16, l1)\n",
    "\n",
    "# --- Define third block with residual connection\n",
    "l3 = conv1(16, l2) + l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection\n",
    "\n",
    "Note that layers can added **only if** the layer sizes match exactly. What happens if the total number of feature maps (e.g. layer depth) is different? The solution is use of the `1 x 1` projection matrix (e.g. convolutional operation without corresponding nonlinearity). Here the third and fourth dimension of the convolutional kernel are designed to match the number of channels in the input and target output tensors, respectively:\n",
    "\n",
    "```\n",
    "filter size = I x J x C0 x C1\n",
    "\n",
    "I  ==> 1\n",
    "J  ==> 1\n",
    "C0 ==> # of channels in input tensor\n",
    "C1 ==> # of channels in output tensor\n",
    "```\n",
    "\n",
    "Recall that in Tensorflow, only the output layer channel size needs to be defined (the third channel of the convolutional kernel is inferred based on the input tensor). Consider the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define blocks\n",
    "l1 = conv1(16, inputs['dat'])\n",
    "l2 = conv1(32, l1)\n",
    "l3 = conv1(32, l2) # + l1 would not work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, `l1` cannot be added since dimensions do not match. Thus consider the following projection operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define projection\n",
    "proj = lambda filters, x : layers.Conv3D(\n",
    "    filters=filters, \n",
    "    strides=1, \n",
    "    kernel_size=(1, 1, 1),\n",
    "    padding='same')(x)\n",
    "\n",
    "# --- Define third block with residual connection\n",
    "l3 = conv1(32, l2) + proj(32, l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about differences not only in channel depth but also feature map size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define blocks\n",
    "l1 = conv1(16, inputs['dat'])\n",
    "l2 = conv2(32, l1)\n",
    "l3 = conv1(32, l2) # + l1 would not work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To match the subsample operation, the projection operation now also must strided as well. Given this, it may be useful to increase the `kernel_size` of the project operation as you recall so that all activations are contributing to the output projection tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define projection\n",
    "proj = lambda filters, x : layers.Conv3D(\n",
    "    filters=filters, \n",
    "    strides=(1, 2, 2), \n",
    "    kernel_size=(1, 1, 1),\n",
    "    padding='same')(x)\n",
    "\n",
    "# --- Define third block with residual connection\n",
    "l3 = conv1(32, l2) + proj(32, l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottleneck\n",
    "\n",
    "In addition to creating matching layer sizes, projection matrices can be used to perform bottleneck operations for convolutional efficiency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define projection\n",
    "proj = lambda filters, x : layers.Conv3D(\n",
    "    filters=filters, \n",
    "    strides=1, \n",
    "    kernel_size=(1, 1, 1),\n",
    "    padding='same')(x)\n",
    "\n",
    "# --- Define standard conv-conv block\n",
    "l1 = conv1(32, inputs['dat'])\n",
    "l2 = conv1(32, l1)\n",
    "\n",
    "# --- Define bottleneck conv-conv block\n",
    "l1 = conv1(32, inputs['dat'])\n",
    "l2 = proj(32, conv1(8, proj(8, l1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the computational efficiency of the bottleneck vs. the standard conv block in this example?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the definition of an Inception module:\n",
    "\n",
    "![Inception](https://raw.githubusercontent.com/peterchang77/dl_tutor/master/cs190/spring_2021/notebooks/detection/pngs/inception.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first implement a naive Inception module without any bottlenecks. Recall that we will need four different paths implemented:\n",
    "\n",
    "* 1x1 convolution\n",
    "* 3x3 convolution\n",
    "* 5x5 convolution\n",
    "* 3x3 max-pool\n",
    "\n",
    "Let us define these building blocks with the following lambda functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define lambda functions\n",
    "conv = lambda x, filters,kernel_size : layers.Conv3D(\n",
    "    filters=filters, \n",
    "    kernel_size=kernel_size, \n",
    "    padding='same')(x)\n",
    "\n",
    "norm = lambda x : layers.BatchNormalization()(x)\n",
    "relu = lambda x : layers.ReLU()(x)\n",
    "pool = lambda x : layers.MaxPool3D(pool_size=(1, 3, 3), strides=1, padding='same')(x)\n",
    "\n",
    "# --- Define 1x1, 3x3 and 5x5 convs\n",
    "conv1 = lambda filters, x : relu(norm(conv(x, filters, kernel_size=(1, 1, 1))))\n",
    "conv3 = lambda filters, x : relu(norm(conv(x, filters, kernel_size=(1, 3, 3))))\n",
    "conv5 = lambda filters, x : relu(norm(conv(x, filters, kernel_size=(1, 5, 5))))\n",
    "mpool = lambda x : relu(norm(pool(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the above implementation, max-pooling is used as a standard layer without any subsampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now use these lambda functions to create a test Inception module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define first layer operation\n",
    "l1 = conv3(16, inputs['dat'])\n",
    "\n",
    "# --- Define four different paths\n",
    "filters = 16\n",
    "p1 = conv1(filters, l1)\n",
    "p2 = conv3(filters, l1)\n",
    "p3 = conv5(filters, l1)\n",
    "p4 = mpool(l1)\n",
    "\n",
    "# --- Concatenate\n",
    "l2 = layers.Concatenate()([p1, p2, p3, p4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed, naive implementation of the Inception module yields large channel depths over time. To avoid this, use bottleneck operations (as above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define first layer operation\n",
    "l1 = conv3(16, inputs['dat'])\n",
    "\n",
    "# --- Define four different paths\n",
    "filters = 4\n",
    "b1 = proj(filters, l1)\n",
    "\n",
    "p1 = conv1(filters, l1)\n",
    "p2 = conv3(filters, b1)\n",
    "p3 = conv5(filters, b1)\n",
    "p4 = proj(filters, mpool(l1))\n",
    "\n",
    "# --- Concatenate\n",
    "l2 = layers.Concatenate()([p1, p2, p3, p4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Squeeze-and-Excite\n",
    "\n",
    "Recall the definition of a squeeze-and-excite module:\n",
    "\n",
    "![SENet](https://pbs.twimg.com/media/DO25715W0AAxIKA.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SE Module\n",
    "\n",
    "The SE module is a simple modification that can be applied to any existing architecture. Starting with the output of any standard convolutional block (e.g., convolution and activation function), the intermediate feature map is scaled by a constant value independently across all channels to *emphasize* the important features for any given single image (or volume). The scaling values are learned via an SE block, which is characterized by several key features:# --- Define stride-1, stride-2 blocks\n",
    "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n",
    "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=(1, 2, 2))))\n",
    "\n",
    "* **squeeze**: collapse of N x N feature maps to 1 x 1 feature vectors via global pooling\n",
    "* **excitation**: two fully connected layers to model channel-wise (feature-wise) interdependencies\n",
    "* **scale**: scaling all feature maps by the learned *excitation* values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start this implementation by creating a first layer feature map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define kwargs dictionary\n",
    "kwargs = {\n",
    "    'kernel_size': (1, 3, 3),\n",
    "    'padding': 'same'}\n",
    "\n",
    "# --- Define lambda functions\n",
    "conv = lambda x, filters, strides : layers.Conv3D(filters=filters, strides=strides, **kwargs)(x)\n",
    "norm = lambda x : layers.BatchNormalization()(x)\n",
    "relu = lambda x : layers.ReLU()(x)\n",
    "\n",
    "# --- Define stride-1, stride-2 blocks\n",
    "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n",
    "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=(1, 2, 2))))\n",
    "\n",
    "# --- Define model\n",
    "l1 = conv1(32,  inputs['dat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following lines of code to modify the output feature map `l1` by a scalar vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Squeeze (global pool)\n",
    "p1 = layers.GlobalAveragePooling3D()(l1)\n",
    "\n",
    "# --- Excitation (reduce channels to 1 / R) ==> in this example set R = 4 arbitrarily\n",
    "ch = int(p1.shape[-1] / 4)\n",
    "f1 = layers.Dense(ch, activation='relu')(p1)\n",
    "\n",
    "# --- Scale (expand channels to original size)\n",
    "scale = layers.Dense(l1.shape[-1], activation='sigmoid')(f1)\n",
    "scale = layers.Reshape((1, 1, 1, l1.shape[-1]))(scale)    \n",
    "\n",
    "# --- Modify l1\n",
    "l1 = l1 * scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that `l1` has been modified, it can be passed to the next layer exactly as before (e.g., with another `conv1(...)` or `conv2(...)` operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Let us compile a temporary model for purposes of demontrating evaluation procedure. Note that in this example, no special motifs are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define convolution parameters\n",
    "kwargs = {\n",
    "    'kernel_size': (1, 3, 3),\n",
    "    'padding': 'same',\n",
    "    'kernel_initializer': 'he_normal'}\n",
    "\n",
    "# --- Define block components\n",
    "conv = lambda x, filters, strides : layers.Conv3D(filters=filters, strides=strides, **kwargs)(x)\n",
    "norm = lambda x : layers.BatchNormalization()(x)\n",
    "relu = lambda x : layers.ReLU()(x)\n",
    "\n",
    "# --- Define stride-1, stride-2 blocks\n",
    "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n",
    "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=(1, 2, 2)))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define model\n",
    "l1 = conv1(32,  inputs['dat'])\n",
    "l2 = conv1(48,  conv2(48,  l1))\n",
    "l3 = conv1(64,  conv2(64,  l2))\n",
    "l4 = conv1(80,  conv2(80,  l3))\n",
    "l5 = conv1(96,  conv2(96,  l4))\n",
    "l6 = conv1(128, conv2(128, l5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition from CNN to MLP\n",
    "\n",
    "At this point of the model, to convert from CNN to MLP architecture, the `(1, N, N, C)` feature maps need to be collapsed into vector form. A `layers.Flatten()` operation may accomplish this by converting our feature map to a single `(1 * N * N * C,)` vector. An alternative to this is to use a `layers.Reshape()` operation to convert our feature map to a `(1, 1, 1, N * N * C)` feature map; subsequently, any additional 3D convolutional operation with kernel size `(1, 1, 1, C-in, C-out)` will be **identical** to a matrix multiply operation.\n",
    "\n",
    "In other words:\n",
    "\n",
    "```\n",
    "input          | output                | output type    | downstream matrix multiply operations\n",
    "---------------------------------------------------------------------------------------------------\n",
    "(1, N, N, C)   | (N * N * C,)          | vector         | layers.Dense(...)\n",
    "(1, N, N, C)   | (1, 1, 1, N * N * C)  | feature map    | layers.Conv3D(filters=...)\n",
    "```\n",
    "\n",
    "In this implementation (and all other tutorial examples) we will use the second option using `layers.Reshape(...)`. The rationale is that while we are currently training with 2D input slices of shape `(1, 240, 240)`, once the model is trained we would like to pass any volume of arbitrary size into the model (e.g., many slices). A global `layers.Flatten()` operation will convert the entire 3D volume into a vector without preserving slice-by-slice information. A `layers.Reshape([-1, 1, 1, N * N * C])` operation however will be able to flexibly handle arbirary shapes.\n",
    "\n",
    "Fo example, let us assume we have an input with z- number of slices:\n",
    "\n",
    "```\n",
    "input          | operation                               | output\n",
    "---------------------------------------------------------------------------------------------------\n",
    "(Z, N, N, C)   | layers.Flatten()                        | (Z * N * N * C,)\n",
    "(Z, N, N, C)   | layers.Reshape([-1, 1, 1, N * N * C])   | (Z, 1, 1, N * N * C)\n",
    "```\n",
    "\n",
    "The output of the `layers.Flatten()` operation is a single vector (e.g., all slices are collapsed). By contrast, the output of the `layers.Reshape(...)` operation by contrast allows for a total of `z` feature vectors each of shape `N * N * C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Extract shape and reshape\n",
    "n0, n1, c = l6.shape[-3:]\n",
    "f0 = layers.Reshape([-1, 1, 1, n0 * n1 * c])(l6)\n",
    "\n",
    "logits = {}\n",
    "logits['tumor'] = layers.Conv3D(filters=2, kernel_size=1, name='tumor')(f0)\n",
    "\n",
    "# --- Create model\n",
    "model = Model(inputs=inputs, outputs=logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "At this point, the model is ready for training using the standard `model.fit(...)` API with our train and valid generators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-memory data\n",
    "\n",
    "For moderate sized datasets which are too large to fit into immediate hard-drive cache, but small enough to fit into RAM memory, it is often times a good idea to first load all training data into RAM memory for increased speed of training. The `client` can be used for this purpose as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load data into memory for faster training\n",
    "client.load_data_in_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "To test the trained model, the following steps are required:\n",
    "\n",
    "* load data\n",
    "* use `model.predict(...)` to obtain logit scores\n",
    "* use `np.argmax(...)` to obtain prediction\n",
    "* compare prediction with ground-truth\n",
    "* serialize in Pandas DataFrame\n",
    "\n",
    "Recall that the generator used to train the model simply iterates through the dataset randomly. For model evaluation, the cohort must instead be loaded manually in an orderly way. For this tutorial, we will create new **test mode** data generators, which will simply load each example individually once for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create validation generator\n",
    "test_train, test_valid = client.create_generators(test=True, expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important note**: although the model is trained using 2D slices, there is nothing to preclude passing an entire 3D volume through the model at one time (e.g. consider that the entire 3D volume is a single *batch* of data). When the`expand=True` flag is set in the `client.create_generators(...)` method above, one of the of the key generator modifications is to yield entire 3D volumes instead of slices.\n",
    "\n",
    "Note that typically performance metrics for medical imaging models are commonly reported on a volume-by-volume basis (not slice-by-slice). However in this example we will simply be evaluating slice-by-slice performance as each patient in this cohort does in fact have a brain tumor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run entire volume through model\n",
    "x, y = next(test_train)\n",
    "logits = model.predict(x['dat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the model properly generate a prediction for every slice in the 3D volume? What is the output shape? If you need to review concepts, please reference the discussion above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Code\n",
    "\n",
    "Use the following lines of code to run prediction through the **valid** cohort generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create validation generator\n",
    "test_train, test_valid = client.create_generators(test=True, expand=True)\n",
    "\n",
    "trues = []\n",
    "preds = []\n",
    "\n",
    "for x, y in test_valid:\n",
    "    \n",
    "    # --- Predict\n",
    "    logits = model.predict(x['dat'])\n",
    "\n",
    "    if type(logits) is dict:\n",
    "        logits = logits['tumor']\n",
    "\n",
    "    # --- Argmax\n",
    "    pred = np.squeeze(np.argmax(logits, axis=-1))\n",
    "\n",
    "    trues.append(y['tumor'].ravel())\n",
    "    preds.append(pred.ravel())\n",
    "\n",
    "trues = np.array(trues).ravel()\n",
    "preds = np.array(preds).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare results in Pandas DataFrame for ease of analysis and sharing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create DataFrame\n",
    "df = pd.DataFrame(index=np.arange(preds.size))\n",
    "\n",
    "# --- Define columns\n",
    "df['true'] = trues\n",
    "df['pred'] = preds\n",
    "df['corr'] = df['true'] == df['pred']\n",
    "\n",
    "# --- Print accuracy\n",
    "print(df['corr'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading a Model\n",
    "\n",
    "After a model has been successfully trained, it can be saved and/or loaded by simply using the `model.save()` and `models.load_model()` methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Serialize a model\n",
    "model.save('./detection.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load a serialized model\n",
    "del model\n",
    "model = models.load_model('./detection.hdf5', compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "Up until this point, this tutorial has presented key implementation details for three advanced CNN motifs: residual operation (with bottleneck); Inception module; Squeeze-and-Excite (SE) module. However the working examples above may become tedious to use in a large network architecture. To facilitate additional organization, consider the following helper methods to generically implement these motifs in various settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Create a general method to facilitate a residual connection between any arbitrary two tensors. Keep in mind that prior to the addition operation, one needs to account for potential feature map differences in:\n",
    "\n",
    "* feature map size\n",
    "* feature map depth\n",
    "\n",
    "Use the following cell to implement this method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual(a, b):\n",
    "    \"\"\"\n",
    "    Method to implement residual connection between two arbitrary tensors (a + b)\n",
    "    \n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hints\n",
    "\n",
    "Consider the following psuedocode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Check to see if projection is needed (how to determine?)\n",
    "\n",
    "# --- If projection is needed:\n",
    "\n",
    "    # --- Account for potential change in feature map depth\n",
    "\n",
    "    # --- Account for potential change in feature map size (subsample)\n",
    "\n",
    "    # --- Modify kernel_size if needed\n",
    "\n",
    "    # --- Perform projection\n",
    "\n",
    "# --- Perform residual operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a general method to facilitate an Inception module for any given single input tensor. Allow for the total number of output feature maps (after concatenation) to be determined dynamically as an argument for the method. Assume that the number of feature maps for each of the four Inception **paths** to yield an equal number of channels.\n",
    "\n",
    "Use the following cell to implement this method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception(a, filters):\n",
    "    \"\"\"\n",
    "    Method to implement Inception module\n",
    "    \n",
    "      p1 = 1 x 1 conv\n",
    "      p2 = BN > 3 x 3 conv\n",
    "      p3 = BN > 5 x 5 conv\n",
    "      p4 = 3 x 3 pool > BN\n",
    "      \n",
    "      BN = bottleneck operation\n",
    "    \n",
    "    :return\n",
    "    \n",
    "      (tf.Tensor) None * i * j * c tensor\n",
    "      \n",
    "        i == a.shape[1]\n",
    "        j == a.shape[2]\n",
    "        c == filters\n",
    "        \n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hints\n",
    "\n",
    "Use the template code from above. The only minor modification that needs to be made is to automatically account for number of output filters in each individual pathway to yield a concatenated filter that is the desired output shape.\n",
    "\n",
    "Consider the following pseudocode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Defiine lambda functions for: conv, proj, norm, relu, pool\n",
    "\n",
    "# --- Define 1x1, 3x3 and 5x5 convs\n",
    "\n",
    "# --- Define requisite filter size for each individual path\n",
    "\n",
    "# --- Define four different paths\n",
    "\n",
    "# --- Create bottlenecked operations\n",
    "\n",
    "# --- Concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Create a general method to facilitate an SE module for any given single input tensor. Allow for the relative amount of compression performed prior to excitation  be determined dynamically as an argument for the method.\n",
    "\n",
    "Use the following cell to implement this method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def se(a, r=4):\n",
    "    \"\"\"\n",
    "    Method to implement squeeze-and-exication module\n",
    "    \n",
    "    :params\n",
    "    \n",
    "      (int) r  : scalar to compress representation\n",
    "      \n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hints\n",
    "\n",
    "Consider the following pseudocode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Squeeze (global pool)\n",
    "\n",
    "# --- Excitation (reduce channels to 1 / R)\n",
    "\n",
    "# --- Scale (expand channels to original size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
